'From Squeak 2.3 of January 14, 1999 on 9 February 1999 at 1:29:49 pm'!"Change Set:		WaveletCodecDate:			9 February 1999Author:			Dan IngallsThis changeSet defines a Codec based on the fast wavelet transform  See the class comments in WaveletCodec for how to use it and directions for future work.Also included are a couple of improvements to the SoundCodec superclass and the MuLawCodec sibling.  The latter make available a protocol for external access to the uLaw encoding and decoding."!SoundCodec subclass: #WaveletCodec	instanceVariableNames: 'fwt samplesPerFrame nLevels alpha beta '	classVariableNames: ''	poolDictionaries: ''	category: 'Music-Synthesis'!!SoundCodec methodsFor: 'subclass responsibilities' stamp: 'di 2/8/1999 14:23'!bytesPerEncodedFrame	"Answer the number of bytes required to hold one frame of compressed sound data. Answer zero if this codec produces encoded frames of variable size."	self subclassResponsibility.! !!SoundCodec methodsFor: 'private' stamp: 'di 2/8/1999 19:53'!decodeCompressedData: aByteArray	"Decode the entirety of the given encoded data buffer with this codec. Answer a monophonic SoundBuffer containing the uncompressed samples."	| frameCount result increments |	frameCount _ self frameCount: aByteArray.	result _ SoundBuffer newMonoSampleCount: frameCount * self samplesPerFrame.	self reset.	increments _ self decodeFrames: frameCount from: aByteArray at: 1 into: result at: 1.	((increments first = aByteArray size) and: [increments last = result size]) ifFalse: [		self error: 'implementation problem; increment sizes should match buffer sizes'].	^ result! !!SoundCodec methodsFor: 'private' stamp: 'di 2/8/1999 14:20'!encodeSoundBuffer: aSoundBuffer	"Encode the entirety of the given monophonic SoundBuffer with this codec. Answer a ByteArray containing the compressed sound data."	| codeFrameSize frameSize fullFrameCount lastFrameSamples result increments finalFrame i lastIncs |	frameSize _ self samplesPerFrame.	fullFrameCount _ aSoundBuffer monoSampleCount // frameSize.	lastFrameSamples _ aSoundBuffer monoSampleCount - (fullFrameCount * frameSize).	codeFrameSize _ self bytesPerEncodedFrame.	codeFrameSize = 0 ifTrue:		["Allow room for 1 byte per sample for variable-length compression"		codeFrameSize _ frameSize].	lastFrameSamples > 0		ifTrue: [result _ ByteArray new: (fullFrameCount + 1) * codeFrameSize]		ifFalse: [result _ ByteArray new: fullFrameCount * codeFrameSize].	self reset.	increments _ self encodeFrames: fullFrameCount from: aSoundBuffer at: 1 into: result at: 1.	lastFrameSamples > 0 ifTrue: [		finalFrame _ SoundBuffer newMonoSampleCount: frameSize.		i _ fullFrameCount * frameSize.		1 to: lastFrameSamples do: [:j |			finalFrame at: j put: (aSoundBuffer at: (i _ i + 1))].		lastIncs _ self encodeFrames: 1 from: finalFrame at: 1 into: result at: 1 + increments second.		increments _ Array with: increments first + lastIncs first							with: increments second + lastIncs second].	increments second < result size		ifTrue: [^ result copyFrom: 1 to: increments second]		ifFalse: [^ result]! !!SoundCodec methodsFor: 'private' stamp: 'di 2/8/1999 19:54'!frameCount: aByteArray	"Compute the frame count for this byteArray.  This default computation will have to be overridden by codecs with variable frame sizes."	| codeFrameSize |	codeFrameSize _ self bytesPerEncodedFrame.	(aByteArray size \\ codeFrameSize) = 0 ifFalse:		[self error: 'encoded buffer is not an even multiple of the encoded frame size'].	^ aByteArray size // codeFrameSize! !!MuLawCodec reorganize!('subclass responsibility' bytesPerEncodedFrame decodeFrames:from:at:into:at: encodeFrames:from:at:into:at: samplesPerFrame)('external access' uLawDecodeSample: uLawEncodeSample:)('private' uLawEncode12Bits:)!!MuLawCodec methodsFor: 'subclass responsibility' stamp: 'di 2/8/1999 22:25'!encodeFrames: frameCount from: srcSoundBuffer at: srcIndex into: dstByteArray at: dstIndex	"Encode the given number of frames starting at the given index in the given monophonic SoundBuffer and storing the encoded sound data into the given ByteArray starting at the given destination index. Encode only as many complete frames as will fit into the destination. Answer a pair containing the number of samples consumed and the number of bytes of compressed data produced."	"Note: Assume that the sender has ensured that the given number of frames will not exhaust either the source or destination buffers."	srcIndex to: srcIndex + frameCount - 1 do: [:i |		dstByteArray at: i put: (self uLawEncodeSample: (srcSoundBuffer at: i))].	^ Array with: frameCount with: frameCount! !!MuLawCodec methodsFor: 'external access' stamp: 'di 2/8/1999 22:28'!uLawDecodeSample: byte	"Decode a 16-bit signed sample from 8 bits using uLaw decoding"	^ DecodingTable at: byte + 1! !!MuLawCodec methodsFor: 'external access' stamp: 'di 2/8/1999 22:30'!uLawEncodeSample: sample	"Encode a 16-bit signed sample into 8 bits using uLaw encoding"	| s |	s _ sample // 8.  "drop 3 least significant bits"	s < 0 ifTrue: [^ (self uLawEncode12Bits: 0-s) + 16r80]		ifFalse: [^ (self uLawEncode12Bits: s)].! !!MuLawCodec methodsFor: 'private' stamp: 'di 2/9/1999 13:25'!uLawEncode12Bits: s	"Encode a 12-bit unsigned sample (0-4095) into 7 bits using uLaw encoding.	This gets called by a method that scales 16-bit signed integers down to a		12-bit magnitude, and then ORs in 16r80 if they were negative.	Detail: May get called with s >= 4096, and this works fine."	s < 496 ifTrue: [		s < 112 ifTrue: [			s < 48 ifTrue: [				s < 16					ifTrue: [^ 16r70 bitOr: (15 - s)]					ifFalse: [^ 16r60 bitOr: (15 - ((s - 16) bitShift: -1))]].			^ 16r50 bitOr: (15 - ((s - 48) bitShift: -2))].		s < 240			ifTrue: [^ 16r40 bitOr: (15 - ((s - 112) bitShift: -3))]			ifFalse: [^ 16r30 bitOr: (15 - ((s - 240) bitShift: -4))]].	s < 2032 ifTrue: [		s < 1008			ifTrue: [^ 16r20 bitOr: (15 - ((s - 496) bitShift: -5))]			ifFalse: [^ 16r10 bitOr: (15 - ((s - 1008) bitShift: -6))]].	s < 4080		ifTrue: [^ 15 - ((s - 2032) bitShift: -7)]		ifFalse: [^ 0].! !!WaveletCodec commentStamp: 'di 2/9/1999 13:19' prior: 0!The Wavelet codec performs a wavelet transform on the original data.  It then achieves its compression by thresholding the transformed data, converting all values below a given magnitude to zero, and then run-coding the resulting data.  The run-coding provides automatic variable compression depending on the parameters chosen.As is, this codec achieves reasonable reproduction at 10:1 compression, although the quality from the GSMCodec is definitely better.  I feel that the quality would be comparable if uLaw scaling were introduced prior to thresholding.The nice thing about using wavelets is there are numerous factors to play with for better performance:	nLevels - the "order" of the transform performed	alpha and beta - these specify the wavelet shape (some are better for speech)	the actual threshold usedBy simply changing these parameters, one can easily vary the compression achieved from 5;1 to 50:1, and listen to the quality at each step.The specific format for an encoded buffer is as follows:	4 bytes: frameCount.	4 bytes: samplesPerFrame.	4 bytes: nLevels.	4 bytes: alpha asIEEE32BitWord.	4 bytes: beta asIEEE32BitWord.	frameCount occurrences of...		2 bytes: frameSize in bytes, not including these 2			may be = 0 for complete silence, meaning no scale even.		4 bytes: scale asIEEE32BitWord.		a series of 8-bit values encoded as follows:			0-200: 	-100..+100 -- 100 represents the full scale value			201-248:	a run of n-200 consecutive 0's			249-255:	a run of (64 128 256 512 1024 2048 4096) consecutive 0's!!WaveletCodec reorganize!('subclass responsibilities' bytesPerEncodedFrame decodeFrames:from:at:into:at: encodeFrames:from:at:into:at: frameCount: samplesPerFrame)!!WaveletCodec methodsFor: 'subclass responsibilities' stamp: 'di 2/8/1999 14:22'!bytesPerEncodedFrame	"Answer the number of bytes required to hold one frame of compressed sound data. Answer zero if this codec produces encoded frames of variable size."	^ 0! !!WaveletCodec methodsFor: 'subclass responsibilities' stamp: 'di 2/9/1999 00:29'!decodeFrames: frameCount from: srcByteArray at: srcIndex into: dstSoundBuffer at: dstIndex	"Decode the given number of monophonic frames starting at the given index in the given ByteArray of compressed sound data and storing the decoded samples into the given SoundBuffer starting at the given destination index. Answer a pair containing the number of bytes of compressed data consumed and the number of decompressed samples produced."	"Note: Assume that the sender has ensured that the given number of frames will not exhaust either the source or destination buffers."	| frameBase sourceI coeffArray scale i c nullCount samples sourceFrameEnd s frameSize iSample |	s _ ReadStream on: srcByteArray from: srcIndex to: srcByteArray size.	"frameCount _ " s nextNumber: 4.	samplesPerFrame _ s nextNumber: 4.	nLevels _ s nextNumber: 4.	alpha _ Float fromIEEE32Bit: (s nextNumber: 4).	beta _ Float fromIEEE32Bit: (s nextNumber: 4).	sourceI _ srcIndex + 20.	fwt ifNil:		["NOTE: This should read parameters from the encoded data"		fwt _ FWT new.		fwt nSamples: samplesPerFrame nLevels: nLevels.		fwt setAlpha: 0.0 beta: 0.0].	frameBase _ dstIndex.	coeffArray _ fwt coeffs.  "A copy that we can modify"	1 to: frameCount do:		[:frame | 		"Decode the scale for this frame"		frameSize _ (ReadStream on: srcByteArray from: sourceI to: srcByteArray size)						nextNumber: 2.		sourceI _ sourceI + 2.		sourceFrameEnd _ frameSize + sourceI.		scale _ Float fromIEEE32Bit:					((ReadStream on: srcByteArray from: sourceI to: srcByteArray size)						nextNumber: 4).		sourceI _ sourceI + 4.		"Expand run-coded samples to scaled float values."		i _ 5.		[i <= coeffArray size]			whileTrue:			[c _ srcByteArray at: sourceI.			sourceI _ sourceI + 1.			c <= 200				ifTrue: [coeffArray at: i put: (c-100) * scale.						i _ i + 1]				ifFalse: [nullCount _ c - 200.						nullCount > 48 ifTrue:							[nullCount _ #(64 128 256 512 1024 2048 4096) at: nullCount-48].						i to: i + nullCount - 1 do: [:j | coeffArray at: j put: 0.0].						i _ i + nullCount]].			"Copy float values into the wavelet sample array"					fwt coeffs: coeffArray.		"Compute the transform"		fwt transformForward: false.		"Determine the scale for this frame"		samples _ fwt samples.		samples size = samplesPerFrame ifFalse: [self error: 'frame size error'].		1 to: samples size do:			[:j | iSample _ (samples at: j) asInteger.			iSample > 32767 ifTrue: [iSample _ 32767].			iSample < -32768 ifTrue: [iSample _ -32768].			dstSoundBuffer at: frameBase + j - 1 put: iSample].		sourceI = sourceFrameEnd ifFalse: [self error: 'frame size error'].		frameBase _ frameBase + samplesPerFrame].	^ Array with: sourceI - srcIndex			with: frameBase - dstIndex! !!WaveletCodec methodsFor: 'subclass responsibilities' stamp: 'di 2/9/1999 01:00'!encodeFrames: frameCount from: srcSoundBuffer at: srcIndex into: dstByteArray at: dstIndex	"Encode the given number of frames starting at the given index in the given monophonic SoundBuffer and storing the encoded sound data into the given ByteArray starting at the given destination index. Encode only as many complete frames as will fit into the destination. Answer a pair containing the number of samples consumed and the number of bytes of compressed data produced."	"Note: Assume that the sender has ensured that the given number of frames will not exhaust either the source or destination buffers."	| frameBase coeffs maxVal minVal c scale nullCount thisCount destI frameI outFrameSize threshold sm |	fwt ifNil:		[samplesPerFrame _ self samplesPerFrame.		threshold _ 10.		nLevels _ 6.		alpha _ 0.0.		beta _ 0.0.		fwt _ FWT new.		fwt nSamples: samplesPerFrame nLevels: nLevels.		fwt setAlpha: alpha beta: beta].	(WriteStream on: dstByteArray from: dstIndex to: dstByteArray size)		nextNumber: 4 put: frameCount;		nextNumber: 4 put: samplesPerFrame;		nextNumber: 4 put: nLevels;		nextNumber: 4 put: alpha asIEEE32BitWord;		nextNumber: 4 put: beta asIEEE32BitWord.	destI _ dstIndex + 20.	frameBase _ srcIndex.	1 to: frameCount do:		[:frame | 		"Copy float values into the wavelet sample array"				fwt samples: ((frameBase to: frameBase + samplesPerFrame-1) 				collect: [:i | (srcSoundBuffer at: i) asFloat]).		"Compute the transform"		fwt transformForward: true.		frameI _ destI.  "Reserve space for frame size"		destI _ destI + 2.		"Determine and output the scale for this frame"		coeffs _ fwt coeffs.		maxVal _ 0.0.  minVal _ 0.0.		5 to: coeffs size do:			[:i | c _ coeffs at: i.			c > maxVal ifTrue: [maxVal _ c].			c < minVal ifTrue: [minVal _ c]].		maxVal _ maxVal max: 5000.0.  "Turn silence into zeroes, not noise"		scale _ (maxVal max: minVal negated) / 100.0.  "Will scale all to -100..100"		(WriteStream on: dstByteArray from: destI to: dstByteArray size)			nextNumber: 4 put: scale asIEEE32BitWord.		destI _ destI + 4.		"Copy scaled values, with run-coded sequences of 0's, to destByteArray"		nullCount _ 0.		5 to: coeffs size do:			[:i | c _ ((coeffs at: i) / scale) asInteger.			c abs < threshold				ifTrue: ["Below threshold -- count nulls."						nullCount _ nullCount + 1]				ifFalse: ["Above threshold -- emit prior null count and this sample."						[nullCount > 0]							whileTrue:							[nullCount >= 64							ifTrue: [thisCount _ 64.  c _ 249.									[c < 255 and: [nullCount >= (thisCount*2)]]										whileTrue: [thisCount _ thisCount*2. c _ c+1].									dstByteArray at: destI put: c]							ifFalse: [thisCount _ nullCount min: 48.									dstByteArray at: destI put: thisCount + 200].							nullCount _ nullCount - thisCount.							destI _ destI + 1].						dstByteArray at: destI put: c + 100.						destI _ destI + 1]].						[nullCount > 0]  "Emit any trailing nullCount"							whileTrue:							[nullCount >= 64							ifTrue: [thisCount _ 64.  c _ 249.									[c < 255 and: [nullCount >= (thisCount*2)]]										whileTrue: [thisCount _ thisCount*2. c _ c+1].									dstByteArray at: destI put: c]							ifFalse: [thisCount _ nullCount min: 48.									dstByteArray at: destI put: thisCount + 200].							nullCount _ nullCount - thisCount.							destI _ destI + 1].		outFrameSize _ destI - frameI - 2.  "Write frame size back at the beginning"		(WriteStream on: dstByteArray from: frameI to: dstByteArray size)			nextNumber: 2 put: outFrameSize.		frameBase _ frameBase + samplesPerFrame].sm _ TextMorph new contents: (((frameBase - srcIndex) *2.0 / (destI - dstIndex) truncateTo: 0.1) printString , ' : 1') asText allBold.sm position: Sensor cursorPoint + (-20@30).World addMorph: sm; doOneCycleNow.sm delete.	^ Array with: frameBase - srcIndex			with: destI - dstIndex! !!WaveletCodec methodsFor: 'subclass responsibilities' stamp: 'di 2/8/1999 16:49'!frameCount: aByteArray	"Compute the frame count for this byteArray.  This default computation will have to be overridden by codecs with variable frame sizes."	^ (ReadStream on: aByteArray) nextNumber: 4.! !!WaveletCodec methodsFor: 'subclass responsibilities' stamp: 'di 2/8/1999 14:17'!samplesPerFrame	"Answer the number of sound samples per compression frame."	^ 4096! !SoundCodec removeSelector: #decodeSoundbytesPerEncodedFrame!WaveletCodec removeSelector: #decodeSoundbytesPerEncodedFrame!WaveletCodec removeSelector: #reset!WaveletCodec removeSelector: #longFromBytes:!WaveletCodec removeSelector: #bytesFromLong:!